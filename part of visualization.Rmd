---
title: "MCMC"
output: 
    pdf_document
---

```{r include=FALSE, echo=FALSE}
library(MASS)
library(tidyverse)
```

### Data preprocessing (same as EDA)

```{r}
origin_df <- read.csv("hurrican703.csv")

hurricane_df <- origin_df %>% 
  mutate(
    Month = factor(Month, levels = month.name[-c(2:3)]), # April-January (January ref, may choose another)
    Nature = as.factor(Nature), # TS,ET,DS,SS,NR (DS ref, may choose another)
    # note: one hurricane can have multiple natures throughout its life
    time = gsub("[()]", "", time),
    time = paste0(ifelse(substr(time, 1, 2) > 23, "19", "20"), time),
    time = as.POSIXct(time, format = "%Y-%m-%d %H:%M:%S"),
    hour = substr(time, 12, 19)
  ) %>% 
  # remove data not at six-hour time intervals. (613 observations)
  filter(hour %in% c("00:00:00", "06:00:00", "12:00:00", "18:00:00")) %>% 
  dplyr::select(-hour)

# remove hurricanes that has only 2 (<3) observations (change the threshold if you wish)
few_id <- hurricane_df %>% 
  group_by(ID) %>% 
  summarize(obs = n()) %>% 
  filter(obs < 3) %>% 
  .$ID
hurricane_df <- hurricane_df %>% filter(!(ID %in% few_id)) # remove 3 hurricanes

# manually correct hurricanes that have same names but are actually different
hurricane_df <- 
  hurricane_df %>% 
  mutate(
    # 2 hurricanes with the name ALICE.1954
    ID = ifelse(ID == "ALICE.1954" & Month == "June", "ALICE.1954(1)", ID),
    ID = ifelse(ID == "ALICE.1954", "ALICE.1954(2)", ID),
    # 4 hurricanes with the name SUBTROP:UNNAMED.1974
    ID = ifelse(ID == "SUBTROP:UNNAMED.1974" & Month == "June", "SUBTROP:UNNAMED.1974(1)", ID),
    ID = ifelse(ID == "SUBTROP:UNNAMED.1974" & Month == "July", "SUBTROP:UNNAMED.1974(2)", ID),
    ID = ifelse(ID == "SUBTROP:UNNAMED.1974" & Month == "August", "SUBTROP:UNNAMED.1974(3)", ID),
    ID = ifelse(ID == "SUBTROP:UNNAMED.1974", "SUBTROP:UNNAMED.1974(4)", ID),
    # 2 hurricanes with the name SUBTROP:UNNAMED.1976
    ID = ifelse(ID == "SUBTROP:UNNAMED.1976" & Month == "May", "SUBTROP:UNNAMED.1976(1)", ID),
    ID = ifelse(ID == "SUBTROP:UNNAMED.1976", "SUBTROP:UNNAMED.1976(2)", ID)
  )
```

### Data partition (may be useless.)

```{r}
# data partition
id <- hurricane_df %>% dplyr::select(ID) %>% unique %>% as.vector %>% unlist
set.seed(1)
index <- sample(1:length(id), size = 0.8*length(id))
training_id <- id[index]
test_id <- id[-index]
Training <- hurricane_df %>% filter(ID %in% training_id)
Test <- hurricane_df %>% filter(ID %in% test_id)
```

### Create $\mathbf{X}$, $\mathbf{Y}$, $\mathbf{Z}$ and $\boldsymbol{m}=(m_i)$ in R

```{r}
n <- length(unique(Training$ID))

Y <- split(Training$Wind.kt, Training$ID) %>% 
  lapply(function(x) x[-c(1:2)])

X <- Training %>% 
  group_by(ID) %>% 
  slice(1) %>% 
  dplyr::select(ID, Season, Month, Nature) %>% 
  ungroup(ID)
X <- model.matrix(~., X[-1])[,-1]

Z <- Training %>% 
  group_by(ID) %>% 
  mutate(
    intercept = 1,
    wind_pre = lag(Wind.kt),
    lat_diff = lag(Latitude) - lag(Latitude, 2),
    long_diff = lag(Longitude) - lag(Longitude, 2),
    wind_diff = lag(Wind.kt) - lag(Wind.kt, 2),
  ) %>% 
  drop_na %>% 
  dplyr::select(ID, intercept, wind_pre, lat_diff, long_diff, wind_diff)
Z <- split(Z[, names(Z)[-1]], Z$ID) %>% 
  lapply(as.matrix)

m <- Training %>% 
  group_by(ID) %>% 
  summarize(obs = n() - 2) %>% 
  .$obs
```

### MCMC

```{r}
B_sample <- function(mu, Sigma, gamma, sigma) {
  Sigma.inv <- solve(Sigma)
  B_mean_cov <- function(i) {
    cov <- solve(Sigma.inv + 1/sigma^2 * t(Z[[i]]) %*% Z[[i]])
    mean <- cov %*% (Sigma.inv %*% mu + 1/sigma^2 * colSums((Y[[i]] - (X[i,] %*% gamma)[,]) * Z[[i]]))
    list(mean = mean, cov = cov)
  }
  mean_cov_list <- lapply(1:n, B_mean_cov)
  B <- sapply(mean_cov_list, function(x) {mvrnorm(mu = x$mean, Sigma = x$cov)})
  return(B)
}

mu_sample <- function(B, Sigma) {
  cov <- V %*% solve(n*V + Sigma)
  mean <- cov %*% rowSums(B)
  mu <- mvrnorm(mu = mean, Sigma = cov)
  return(mu)
}

Sigma_sample <- function(B, mu) {
  Sigma.inv <- rWishart(n = 1, Sigma = S + (B - mu) %*% t(B - mu), df = n + nu)[,,]
  Sigma <- solve(Sigma.inv)
  return(Sigma)
}

gamma_sample <- function(B, sigma) {
  X_trans <- sqrt(m) * X
  cov <- solve(400*diag(14) + 1/sigma^2 * t(X_trans) %*% X_trans)
  total <- rowSums(sapply(1:n, function(i) sum(Z[[i]] %*% B[,i] - Y[[i]]) * X[i,]))
  mean <- cov %*% (-1/sigma^2 * total)
  gamma <- mvrnorm(mu = mean, Sigma = cov)
  return(gamma)
}

# MH algorithm (random walk)
sigma_sample <- function(sigma, B, gamma, a) {
  sigma_new <- sigma + (runif(1) - 0.5) * 2 * a # candidate sigma
  if (sigma_new <= 0) {
    return(sigma)
  }
  RSS <- sum(sapply(1:n, function(i) sum((Y[[i]] - Z[[i]] %*% B[,i] - (X[i,] %*% gamma)[,])^2)))
  log_kernal_ratio <- -sum(m) * log(sigma_new/sigma) +
    log(1 + (sigma/10)^2) - log(1 + (sigma_new/10)^2) -
    0.5 * (1/sigma_new^2 - 1/sigma^2) * RSS
  log_prob <- min(0, log_kernal_ratio)
  sigma <- ifelse(log_prob > log(runif(1)), sigma_new, sigma)
  return(sigma)
}

MCMC <- function(B0, mu0, Sigma0, gamma0, sigma0, a, iter) {
  B <- B0
  mu <- mu0
  Sigma <- Sigma0
  gamma <- gamma0
  sigma <- sigma0
  res <- vector("list", iter)
  for (i in 1:iter) {
    B <- B_sample(mu, Sigma, gamma, sigma)
    mu <- mu_sample(B, Sigma)
    Sigma <- Sigma_sample(B, mu)
    gamma <- gamma_sample(B, sigma)
    sigma <- sigma_sample(sigma, B, gamma, a)
    res[[i]] <- list(B = B, mu = mu, Sigma = Sigma, gamma = gamma, sigma = sigma)
  }
  return(res)
}
```

### Apply MCMC on training data

1. Please select appropriate $\boldsymbol V$ and $\boldsymbol S$ values.
2. Please select appropriate starting values for parameters, especially $\mathbf{B}$.
3. You can save the results `xxx_list` as csv files or otherwise. Note that we need to find the answers to the above 2 problems and also the following questions to make sure that we won't make any updates for these saved data:

* Should we apply MCMC on training hurricanes or all hurricanes? (in other words, should we partition the data into training and test data?) This relies on whether we hope to make predictions only on test hurricanes or on hurricanes used for MCMC.
* Given that samples of $\mathbf{B}$ is a 10000*2815 matrix, and we only use $\mathbf{B}$ for predictions on hurricanes used for MCMC, we can decide which hurricanes we are gonna predict (e.g., hurricanes having appropriate number of observations, famous hurricanes, hurricanes of different natures, years, months), and only save the samples of corresponding $\boldsymbol\beta_i$'s.
* We need to run the MCMC function and save the results (`xxx_list`) after we solve the above 3 problems. Then we need to check whether the `a` in the random walk for sampling $\sigma$ is appropriate. (acceptance rate 30% - 60%, see far below) If not, we need to change `a` and regenerate the results.

estimated running time: 10 mins for 10,000 iterations

```{r}
# constants
nu <- 5 # suggested
V <- diag(5) # can try other. see requirement
S <- diag(5) # can try other. see requirement

# initial values of variables (please try other)
B0 <- matrix(rep(0, 5*n), ncol = n, nrow = 5) # each column is beta_i
mu0 <- rep(0, 5)
Sigma0 <- diag(5)
gamma0 <- rep(0, 14)
sigma0 <- 10
iternum=10000
set.seed(1)
res <- MCMC(B0, mu0, Sigma0, gamma0, sigma0, a = 0.12, iter = iternum) # try larger values
res[[1]]$B
# B. beta_i_j: i: ith hurricane, j: 1-5
B_list <- t(mapply(function(x) x$B, res))
B_names <- apply(expand.grid(0:4, 1:n), 1,
                 function(x) paste("beta", x[2], x[1], sep = "_"))
colnames(B_list) <- B_names
# mu
mu_list <- t(mapply(function(x) x$mu, res))
colnames(mu_list) <- colnames(Z[[1]])
# Sigma (symmetric)
Sigma_list <- t(mapply(function(x) x$Sigma, res))
Sigma_names <- apply(expand.grid(1:5, 1:5), 1,
                     function(x) paste("Sigma_", x[2], x[1], sep = ""))
colnames(Sigma_list) <- Sigma_names
# gamma (month ref: January, nature ref: DS)
gamma_list <- t(mapply(function(x) x$gamma, res))
# sigma
sigma_list <- mapply(function(x) x$sigma, res)

write.csv(B_list[,1:100], file = "./data/B_list_partial.csv", row.names = FALSE) # e.g. first 20 hurricanes
write.csv(mu_list, file = "./data/mu_list.csv", row.names = FALSE)
write.csv(Sigma_list, file = "./data/Sigma_matrix_list.csv", row.names = FALSE)
write.csv(gamma_list, file = "./data/gamma_list.csv", row.names = FALSE)
write.csv(sigma_list, file = "./data/sigma_list.csv", row.names = FALSE)
```

### Resulting plots (not complete)

Please make time series plots for all parameters to see if and from which index their samples converge. (may not need for $\mathbf{B}$, since it has $5n$ parameters (5 for each hurricane))

Please also make autocorrelation plots.

```{r fig.height=5, fig.width=8}
beta_list <- read.csv("./data/B_list_partial.csv")
mu_list <- read.csv("./data/mu_list.csv")
Sigma_list <- read.csv("./data/Sigma_matrix_list.csv")
gamma_list <- read.csv("./data/gamma_list.csv")
sigma_list <- read.csv("./data/sigma_list.csv")$x

plot(gamma_list[,1], type = "l") # e.g. plot gamma1 (year)
plot(mu_list[,5], type = "l") # plot mu5 (wind_diff)
plot(sigma_list, type = "l") # plot sigma
```
Visualization for beta
```{r}
beta_list_list <- vector(mode = "list", length = ncol(beta_list)/5)
for (i in 1:length(beta_list_list)) {
  beta_list_list[[i]] <- list()
}

for (i in 1:(ncol(beta_list)/5)) {
  for (j in 1:5) {
    beta_list_list[[i]][[j]] <- beta_list[, (5*(i-1)+j)]
  }
}

```


```{r}
library(ggplot2)
library(gridExtra)

# Extract the number of hurricanes
n_hurricanes <- length(beta_list_list)

# Create an empty list
plot_list <- vector(mode = "list", length = n_hurricanes)

# Loop over each hurricane
for (i in 1:n_hurricanes) {
  # Extract all the parameters for the current hurricane
  beta_hurricane <- beta_list_list[[i]]
  
  # Extract the number of parameters
  n_params <- length(beta_hurricane)
  
  # Create an empty list
  plot_list_hurricane <- vector(mode = "list", length = 2 * n_params)
  
  # Loop over each parameter
  for (j in 1:n_params) {
    # Extract the iterations for the current parameter
    beta_param <- beta_hurricane[[j]]
    
    # Create a line plot
    p1 <- ggplot(data.frame(iteration = 1:iternum, beta = beta_param), aes(x = iteration, y = beta)) +
      geom_line() +
      labs(x = "Iteration", y = "Beta", title = paste(i, "th Hurricane Parameter Plot", j)) +
      theme_bw()
    
    # Create a histogram
    p2 <- ggplot(data.frame(beta = beta_param), aes(x = beta)) +
      geom_histogram(binwidth = 0.05, fill = "gray", color = "black") +
      labs(x = "Beta", y = "Frequency", title = paste(i, "th Hurricane Parameter Plot", j)) +
      theme_bw()
    
    # Store the plots in a list
    plot_list_hurricane[[2*j-1]] <- p1
    plot_list_hurricane[[2*j]] <- p2
  }
  
  # Store all the plots for the current hurricane in a list
  plot_list[[i]] <- grid.arrange(grobs = plot_list_hurricane, ncol = 2)
}

# Combine all the plots into a single plot
grid.arrange(grobs = plot_list, ncol = 2)


```


### Burn in (based on resulting plots)

`xxx_sample` will be used for doing inference (estimates, CI, hypothesis test) and making predictions.

Please select "burn in" numbers based on all time series plots and autocorrelation plots.

```{r}
burn <- 500 # burn in the MC chains. change this based on the resulting plots
index <- (burn + 1):length(res) # index of useful samples (used for estimates & CIs)
beta_sample <- beta_list[index,]
mu_sample <- mu_list[index,]
Sigma_sample <- Sigma_list[index,] # may be useless
gamma_sample <- gamma_list[index,]
sigma_sample <- sigma_list[index] # may be useless
```

### Acceptance rate for $\sigma$ samples

30% - 60% is good. if not, please change `a` in random walk. If really need to change `a`, you need to rerun the MCMC function and update the results saved in the files.

```{r}
length(unique(sigma_list[index]))/length(sigma_list[index])
```