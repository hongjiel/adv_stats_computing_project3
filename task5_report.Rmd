---
title: "P8160 Report - Bayesian Modeling of Hurricane Trajectories"
author: "Hongjie Liu, Xicheng Xie, Jiajun Tao, Zijian Xu, Shaohan Chen"
date: "5/1/2023"
output:
  pdf_document:
    number_sections: true
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
- \usepackage{algorithm} 
- \usepackage{algpseudocode} 
- \usepackage{amsthm}
- \usepackage{bm}
- \usepackage{subfigure}
- \usepackage{graphicx}
- \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
```

\newpage 
# Introduction
## Background
A hurricane is a powerful tropical storm characterized by high winds, heavy rain, storm surges, and flooding. Hurricanes are also known as cyclones or typhoons, depending on the region where they occur.

Hurricanes typically form over warm ocean waters and can travel for thousands of miles, causing widespread destruction and disruption to communities in their path. They are categorized on a scale of 1 to 5 based on their wind speed and potential for damage, with Category 5 being the most severe.

Hurricanes can cause significant damage to infrastructure, homes, and businesses, and can also result in loss of life. As such, it is essential to take precautions and follow instructions from emergency management officials in the event of a hurricane.

## Motivation
Climate researcher are interested in modeling hurricane trajectories for early warning and preparedness, resource allocation, planning and response, and scientific research. Overall, accurate modeling of hurricane trajectories is essential for mitigating the impact of hurricanes on communities, infrastructure, and the environment, as well as for advancing our scientific understanding of these powerful storms.

In this project, we are particularly interested in forecasting the wind speed of hurricanes.

## Dataset
The dataset, `hurrican703.csv`, collected the track data of 702 hurricanes in the North Atlantic area from 1950 to 2013. For all the storms, their location (longitude & latitude) and maximum wind speed were recorded every 6 hours. The data includes the following variables:
\begin{itemize}
\item ID: ID of the hurricanes
\item Season: In which year the hurricane occurred
\item Month: In which month the hurricane occurred
\item Nature: Nature of the hurricane
  
  ET: Extra Tropical
  
  DS: Disturbance
  
  NR: Not Rated
  
  SS: Sub Tropical
  
  TS: Tropical Storm

\item Time: dates and time of the record
\item Latitude and Longitude: The location of a hurricane check point
\item Wind.kt: Maximum wind speed (in Knot) at each check point
\end{itemize}

## Data pre-processing
First we need to pre-process the data. We only kept observations that occurred on 6 consecutive hour intervals. Through this step, we found that some hurricanes had the same ID but were actually different ones (e.g. ALICE.1954). Hurricanes that had fewer than 3 observations were excluded. For the purpose of seasonal comparison, we defined August, September, and October as hurricane-active season, and the rest as hurricane-inactive season. After data cleaning, there are 21691 observations across 704 unique hurricanes.

# Bayesian Hierarchical Model for Wind Speed

## Proposed Model

Let $Y_{i}(t)$ denote the wind speed of the $i$th hurricane at time $t$ (in hours) since the hurricane began. We propose a Bayesian model to characterize the wind speed of the $i$th hurricane 6 hours later as follows:
$$Y_{i}(t+6) =\beta_{0,i}+\beta_{1,i}Y_{i}(t) + \beta_{2,i}\Delta_{i,1}(t)+
\beta_{3,i}\Delta_{i,2}(t) +\beta_{4,i}\Delta_{i,3}(t) + \mathbf{X}_i^\top\boldsymbol\gamma+ \epsilon_{i}(t),$$
where $\Delta_{i,1}(t)$, $\Delta_{i,2}(t)$ and $\Delta_{i,3}(t)$ are the changes of latitude, longitude and wind speed between $t-6$ and $t$, $\boldsymbol{\beta}_{i} = (\beta_{0,i},\beta_{1,i},...,\beta_{4,i})^\top$ are the random coefficients, and $\mathbf{X}_i = (x_{i,1},\ldots,x_{i,6})^\top$ are covariates with fixed effects $\boldsymbol\gamma$. Here, $x_{i,1}$ is the calendar year of the $i$-th hurricane measured with respect to 1950, $x_{i,2}$ is the indicator variable of the month in active season (August-October) when the $i$-th hurricane started, and $x_{i,3},\ldots,x_{i,6}$ are indicator variables of the four types (ES, NR, SS, and TS) of the $i$-th hurricane when it began. We assume that the error term $\epsilon_{i}(t)\sim N(0,\sigma^2)$ and is independent across $t$.

## Prior Distribution for Each Parameter

We consider the prior distribution of the random coefficients $\boldsymbol{\beta}_{i}$'s as a multivariate normal distribution with mean vector $\boldsymbol{\mu}$ and covariance matrix $\boldsymbol{\Sigma}$:
$$\boldsymbol{\beta}_{i} \overset{i.i.d.}{\sim} N(\boldsymbol{\mu}, \boldsymbol{\Sigma}),$$
where $\boldsymbol{\mu}$ and $\boldsymbol{\Sigma}$ are also model parameters. We consider the prior of $\boldsymbol{\mu}$ as a multivariate normal distribution with mean vector $\boldsymbol{0}$ and covariance matrix $\boldsymbol{V}$, and the prior of $\boldsymbol{\Sigma}$ as an inverse-Wishart distribution with degrees of freedom $\nu$ and scale matrix $\boldsymbol{S}$:
$$\begin{aligned}\boldsymbol{\mu}&\sim N(\boldsymbol{0},\boldsymbol{V}),\\
\boldsymbol{\Sigma}&\sim\mathcal{W}^{-1}(\boldsymbol{S},\nu),
\end{aligned}$$
where $\boldsymbol{V}$, $\boldsymbol{S}$, and $\nu$ are model hyperparameters. We set $\boldsymbol{V}$ and $\boldsymbol{S}$ to be identity matrix $\boldsymbol I_5$, reflecting the prior knowledge that the coefficients are largely independent across hurricanes, and the covariance matrix should be diagonal or nearly diagonal. We set the degrees of freedom $\nu=5$ to reflect a relatively weak prior.

For the fixed effect coefficients $\boldsymbol \gamma=(\gamma_1,\ldots,\gamma_6)^\top$, we assume that each $\gamma_k$ ($k=1,\ldots,6$) i.i.d. follows a normal distribution with mean 0 and variance $0.05^2$:
$$\boldsymbol \gamma\sim N(\boldsymbol 0,0.05^2\boldsymbol I_{6}).$$

For the error term, we assume the prior of $\sigma$ is a half-Cauchy distribution with scale parameter 10, reflecting the prior knowledge that the residual variance should be positive and large enough to account for any unexplained variability in the wind speed data.


## Joint Posterior Distribution of Model Parameters

### Joint Prior Distribution

Denote $n$ as the number of observed hurricanes and denote $\mathbf{B}= (\boldsymbol{\beta}_{1}^\top,...,\boldsymbol{\beta}_{n}^\top)^\top$. The joint prior distribution of $\Theta=(\mathbf{B}^\top,\boldsymbol{\mu}^\top, \boldsymbol\Sigma,\boldsymbol\gamma^\top,\sigma^2)$ is given by
\begin{align*}
\pi(\Theta)=&\ \pi(\mathbf{B}^\top,\boldsymbol{\mu}^\top,\boldsymbol{\Sigma},\boldsymbol\gamma^\top,\sigma)\\
=&\ \pi(\mathbf{B}^\top\mid\boldsymbol{\mu}^\top,\boldsymbol{\Sigma})\pi(\boldsymbol{\mu}^\top,\boldsymbol{\Sigma})\pi(\boldsymbol\gamma)\pi(\sigma)\\
=&\ \left(\prod_{i=1}^n\pi(\boldsymbol\beta_i^\top\mid\boldsymbol{\mu}^\top,\boldsymbol{\Sigma})\right)\pi(\boldsymbol{\mu})\pi(\boldsymbol{\Sigma})\pi(\boldsymbol\gamma)\pi(\sigma)\\
=&\ \prod_{i=1}^n\left[(2\pi)^{-5/2}|\boldsymbol{\Sigma}|^{-1/2}\exp\left(-\frac{1}{2}(\boldsymbol\beta_i-\boldsymbol\mu)^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol\beta_i-\boldsymbol\mu)\right)\right] \qquad\qquad\qquad\qquad\qquad\qquad\qquad\;\, \boldsymbol\beta_i\sim N(\boldsymbol{\mu},\boldsymbol{\Sigma})\\
&\ \times(2\pi)^{-5/2}|\boldsymbol{V}|^{-1/2}\exp\left(-\frac{1}{2}\boldsymbol\mu^\top\boldsymbol{V}^{-1}\boldsymbol\mu\right) \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \boldsymbol{\mu}\sim N(\boldsymbol{0},\boldsymbol{V})\\
&\ \times\frac{|\boldsymbol{S}|^{\nu/2}}{2^{5\nu/2}\Gamma_5(\nu/2)}|\boldsymbol{\Sigma}|^{-(\nu+6)/2}\exp\left(-\frac{1}{2}\mathrm{tr}(\boldsymbol{S}\boldsymbol{\Sigma}^{-1})\right) \quad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \boldsymbol{\Sigma}\sim \mathcal{W}^{-1}(\boldsymbol{S},\nu)\\
&\ \times(2\pi)^{-6/2}\cdot20^{6}\cdot\exp\left(-\frac{1}{2}\cdot20^2\cdot\boldsymbol\gamma^\top\boldsymbol\gamma\right) \;\ \quad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \boldsymbol\gamma\sim N(\boldsymbol 0,0.05^2\boldsymbol I_{6})\\
&\ \times\frac{2}{10\pi}\cdot\frac{I(\sigma>0)}{1+(\sigma/10)^2} \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\, \sigma\sim \text{half-Cauchy}(0,10)\\
\propto &\ |\boldsymbol{\Sigma}|^{-(n+\nu+6)/2}\frac{I(\sigma>0)}{1+(\sigma/10)^2}\exp\Bigg[-\frac{1}{2}\Bigg(\sum_{i=1}^n(\boldsymbol\beta_i-\boldsymbol\mu)^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol\beta_i -\boldsymbol\mu)+\boldsymbol\mu^\top\boldsymbol{V}^{-1}\boldsymbol\mu+\mathrm{tr}(\boldsymbol{S}\boldsymbol{\Sigma}^{-1})+400\|\boldsymbol\gamma\|_2^2\Bigg)\Bigg].
\end{align*}


### Likelihood Function

Let $m_i$ denote the number of observations, excluding the first two observations and let $\boldsymbol{Y}_i=(Y_{i,1},\ldots Y_{i,m_i})^\top$ denote the wind speed data of the $i$-th hurricane, excluding the first two observations, where $Y_{i,j}=Y_i(6j+6)$. Denote $\boldsymbol{Y}=(\boldsymbol{Y}_1^\top,\boldsymbol{Y}_2^\top,\ldots,\boldsymbol{Y}_n^\top)^\top$ and $\mathbf Z_{i,j}=(1,Y_{i,j},\Delta_{i,1}(6j+6),\Delta_{i,2}(6j+6),\Delta_{i,3}(6j+6))^\top$.

Given that
$$Y_{i,j}\mid \mathbf{B}^\top,\boldsymbol\gamma^\top,\sigma\overset{i.i.d.}{\sim} N(\mathbf Z_{i,j-1}^\top\boldsymbol\beta_i + \mathbf{X}_i^\top\boldsymbol\gamma,\sigma^2),\qquad\forall i=1,\ldots,n,\; j=1,\cdots,m_i$$
The likelihood function of parameters $\Theta=(\mathbf{B}^\top,\boldsymbol{\mu}^\top, \boldsymbol\Sigma,\boldsymbol\gamma^\top,\sigma^2)$ is given by
$$\begin{aligned}
L_{\boldsymbol{Y}}(\Theta)=&\ \prod_{i=1}^nL_{\boldsymbol{Y}_i}(\mathbf{B}^\top,\boldsymbol{\mu}^\top,\boldsymbol{\Sigma},\boldsymbol\gamma^\top,\sigma)\\
=&\ \prod_{i=1}^n\prod_{j=1}^{m_i}L_{Y_{i,j}}(\boldsymbol\beta_i^\top,\boldsymbol\gamma^\top,\sigma)\\
=&\ \prod_{i=1}^n\prod_{j=1}^{m_i}\left[\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(Y_{i,j}-\mathbf Z_{i,j-1}^\top\boldsymbol\beta_i-\mathbf{X}_i^\top\boldsymbol\gamma)^2}{2\sigma^2}\right)\right]\\
=&\ \left(\prod_{i=1}^n(\sqrt{2\pi}\sigma)^{-m_i}\right)\cdot\exp\left(-\frac{1}{2\sigma^2}\sum_{i=1}^n\sum_{j=1}^{m_i}(Y_{i,j}-\mathbf Z_{i,j-1}^\top\boldsymbol\beta_i-\mathbf{X}_i^\top\boldsymbol\gamma)^2\right).
\end{aligned}$$

### Joint Posterior Distribution

The joint posterior distribution of $\Theta=(\mathbf{B}^\top,\boldsymbol{\mu}^\top, \boldsymbol\Sigma,\boldsymbol\gamma^\top,\sigma^2)$ is given by
\begin{align}
\pi(\Theta\mid \boldsymbol{Y}^\top)
\propto &\ L_{\boldsymbol{Y}}(\Theta)\pi(\Theta)\nonumber\\
\propto &\ \frac{|\boldsymbol{\Sigma}|^{-(n+\nu+6)/2}}{1+(\sigma/10)^2}\exp\left[-\frac{1}{2}\left(\sum_{i=1}^n(\boldsymbol\beta_i-\boldsymbol\mu)^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol\beta_i-\boldsymbol\mu)+\boldsymbol\mu^\top\boldsymbol{V}^{-1}\boldsymbol\mu+\mathrm{tr}(\boldsymbol{S}\boldsymbol{\Sigma}^{-1})+400\|\boldsymbol\gamma\|_2^2\right)\right]\nonumber\\
&\ \times I(\sigma>0)\sigma^{-\sum_{i=1}^n m_i}\exp\left(-\frac{1}{2\sigma^2}\sum_{i=1}^n\sum_{j=1}^{m_i}(Y_{i,j}-\mathbf Z_{i,j-1}^\top\boldsymbol\beta_i-\mathbf{X}_i^\top\boldsymbol\gamma)^2\right).\label{post}
\end{align}

## Conditional Posterior Distribution for Each Parameter

We aim to sample each parameter from the joint posterior distribution $\pi(\Theta\mid \boldsymbol{Y}^\top)$, but but direct sampling is impractical. Fortunately, the proposed Bayesian model includes several conditionally conjugate priors, which facilitate posterior computations using a hybrid Metropolis-Hastings/Gibbs algorithm. Given that $\pi(\Theta\mid \boldsymbol{Y}^\top)$ takes the form (\ref{post}), the conditional posterior distribution for each parameter is as follows:

1. $\boldsymbol\beta_i\mid \boldsymbol{\mu}^\top,\boldsymbol{\Sigma},\boldsymbol\gamma^\top,\sigma,\boldsymbol{Y}^\top$ follows a multivariate normal distribution with mean vector
$$\left(\boldsymbol{\Sigma}^{-1}+\frac{1}{\sigma^2}\sum_{j=1}^{m_i}\mathbf Z_{i,j-1}\mathbf Z_{i,j-1}^\top\right)^{-1}\left(\boldsymbol{\Sigma}^{-1}\boldsymbol\mu+\frac{1}{\sigma^2}\sum_{j=1}^{m_i}(Y_{i,j}-\mathbf{X}_i^\top\boldsymbol\gamma)\mathbf Z_{i,j-1}\right)$$
and covariance matrix $$\left(\boldsymbol{\Sigma}^{-1}+\frac{1}{\sigma^2}\sum_{j=1}^{m_i}\mathbf Z_{i,j-1}\mathbf Z_{i,j-1}^\top\right)^{-1}.$$
2. $\boldsymbol{\mu}\mid \mathbf{B}^\top,\boldsymbol{\Sigma},\boldsymbol\gamma^\top,\sigma,\boldsymbol{Y}^\top$ follows a multivariate normal distribution with mean vector $$\boldsymbol V(n\boldsymbol V+\boldsymbol\Sigma)^{-1}\left(\sum_{i=1}^n\boldsymbol\beta_i\right)$$ and covariance matrix $$\boldsymbol V(n\boldsymbol V+\boldsymbol\Sigma)^{-1}.$$
3. $\boldsymbol{\Sigma}\mid \mathbf{B}^\top,\boldsymbol{\mu}^\top,\boldsymbol\gamma^\top,\sigma,\boldsymbol{Y}^\top$ follows an inverse-Wishart distribution with degrees of freedom $(n+\nu)$ and scale matrix  $$\boldsymbol{S}+\sum_{i=1}^n(\boldsymbol\beta_i-\boldsymbol\mu)(\boldsymbol\beta_i-\boldsymbol\mu)^\top.$$
4. $\boldsymbol\gamma\mid \mathbf{B}^\top,\boldsymbol{\mu}^\top,\boldsymbol{\Sigma},\sigma,\boldsymbol{Y}^\top$ follows a multivariate normal distribution with mean vector $$\left(400\boldsymbol I+\frac{1}{\sigma^2}\sum_{i=1}^nm_i\mathbf{X}_i\mathbf{X}_i^\top\right)^{-1}\left(-\frac{1}{\sigma^2}\sum_{i=1}^n\sum_{j=1}^{m_i}(\mathbf Z_{i,j-1}^\top\boldsymbol\beta_i-Y_{i,j})\mathbf{X}_i\right)$$ and covariance matrix $$\left(400\boldsymbol I+\frac{1}{\sigma^2}\sum_{i=1}^nm_i\mathbf{X}_i\mathbf{X}_i^\top\right)^{-1}.$$

Because of conjugacy, the parameters $\boldsymbol\beta_i$, $\boldsymbol{\mu}$, $\boldsymbol{\Sigma}$, and $\boldsymbol\gamma$ can be easily updated in a Gibbs sampling fashion. The details of derivation can be found in the appendix.

The conditional posterior distribution of $\sigma$ can be expressed as
$$\pi(\sigma\mid \mathbf{B}^\top,\boldsymbol{\mu}^\top,\boldsymbol{\Sigma},\boldsymbol\gamma^\top,\boldsymbol{Y}^\top) \propto\ I(\sigma>0)\frac{\sigma^{-\sum_{i=1}^n m_i}}{1+(\sigma/10)^2}\exp\left(-\frac{1}{2\sigma^2}\sum_{i=1}^n\sum_{j=1}^{m_i}(Y_{i,j}-\mathbf Z_{i,j-1}^\top\boldsymbol\beta_i-\mathbf{X}_i^\top\boldsymbol\gamma)^2\right).$$
We propose to sample $\sigma$ using a Metropolis-Hastings (MH) step with a uniform proposal
distribution.


# MCMC

## Methods of MCMC
To estimate the parameters of the posterior distribution corresponding to the above calculation by collecting samples, we will use the MCMC method. We will apply Gibbs sampling steps to the parameters of the known conditional distribution, and use the Metropolis-Hastings (MH) method for the parameters of the unknown conditional distribution, specifically for $\sigma$. For the other parameters, we will use Gibbs sampling.

Before explaining the algorithm in detail, let's define the hyperparameters:
- $\lambda$ is the acceptance rate of the MH algorithm.
- $a$ represents the search window used in the MH algorithm.
- $burnin$ indicates the starting iteration number for collecting samples.

To begin this algorithm, for each iteration, we firstly Initialize the values of $\boldsymbol{\beta}_i^{(0)}$ $\boldsymbol{\mu}^{(0)}$,$\boldsymbol{\Sigma}^{(0)}$, $\boldsymbol\gamma^{(0)}$, $\sigma^{(0)}$to some value we obtain from lmm model. 

- Next For each iteration $k=1,2,\ldots,N_{iter}$:  
Sample $\boldsymbol{\beta}_i^{(k)}$ from $\pi(\boldsymbol\beta_i\mid \boldsymbol{\mu}^{(k-1)},\boldsymbol{\Sigma}^{(k-1)},\boldsymbol\gamma^{(k-1)},\sigma^{(k-1)},\boldsymbol{Y}^\top)$  
Sample $\boldsymbol{\mu}^{(k)}$ from $\pi(\boldsymbol{\mu}\mid\mathbf B^{(k)}, \boldsymbol{\Sigma}^{(k-1)},\boldsymbol{\gamma}^{(k-1)}, \sigma^{(k-1)}, \boldsymbol{Y}^\top)$  
Sample $\boldsymbol{\Sigma}^{(k)}$ from $\pi(\boldsymbol{\Sigma}\mid \mathbf B^{(k)}, \boldsymbol{\mu}^{(k)}, \boldsymbol\gamma^{(k-1)}, \sigma^{(k-1)}, \mathbf{Y}^\top)$  
Sample $\boldsymbol{\gamma}^{(k)}$ from $\pi(\boldsymbol{\gamma}\mid \mathbf B^{(k)}, \boldsymbol{\mu}^{(k)}, \boldsymbol\Sigma^{(k)},\sigma^{(k-1)}, \mathbf{Y}^\top)$

- For each MH step, after obtaining $\boldsymbol{\beta}_i^{(k)}$, $\boldsymbol{\mu}^{(k)}$, $\boldsymbol{\Sigma}^{(k)}$, and $\boldsymbol\gamma^{(k)}$ in the $k^{th}$ iteration, we assume that $\sigma^{k}_i$ follows a U($\sigma^{k-1}_i$-a, $\sigma^{k-1}_i$+a) distribution. Then, we generate a candidate $\sigma^*$ from that distribution and calculate the acceptance ratio $\lambda$.\par $\lambda=\frac{\pi(\sigma^*|\mathbf{Y}, \boldsymbol{\beta}^{(k)}, \boldsymbol{\mu}^{(k)}, \boldsymbol{\Sigma}^{(k)},\boldsymbol\gamma^{(k)})}{\pi(\sigma^{(k-1)}|\mathbf{Y}, \boldsymbol{\beta}^{(k)}, \boldsymbol{\mu}^{(k)}, \boldsymbol{\Sigma}^{(k)}, \boldsymbol\gamma^{(k)})}$\par
At the same time we compute the acceptance probability, $\alpha$, as the minimum of 1 and the acceptance ratio: $\alpha=\min(1,\lambda)$. We compare that number with a random number $u$ from a uniform distribution, $\text{Uniform}(0,1)$.If $u \leq \alpha$, accept the proposed value and set $\sigma^{(k)} = \sigma^*$, otherwise reject the proposed value and set $\sigma^{(k)} = \sigma^{(k-1)}$.

- Repeat this loop for a total of $N_{iter}=10000$ times, recording the sample values of each parameter.

## Starting Value of MCMC
\textbf{Initial Value Selection}
\begin{itemize}
\item $\boldsymbol{\beta}_i$: This can be obtained through the random effects term in the lmm model. The random effects term can be added to the fixed effects term to obtain $\boldsymbol{\beta}_i^{(0)}$.
\item $\boldsymbol{\mu}$: This can be obtained through the fixed effects of intercept, windpre, latdiff, longdiff, winddiff term.
\item $\boldsymbol{\gamma}$: This can be obtained through the fixed effects of Year, Active Month, and Nature term.
\item $\sigma$: This can be obtained through the model residual.
\item $\boldsymbol{\Sigma}$: This can be obtained through the `VarCorr` function which returns the covariance matrix of the random effects in the model $\boldsymbol{\Sigma}^{(0)}$.
\end{itemize}

\textbf{Specific Value}
\begin{table}[h]
    \centering
    \caption{Initial Value Setting}
    \begin{tabular}{|c|c|}
        \hline
        Parameter & Value \\
        \hline
        $\boldsymbol{\mu}^\top$ & $(24.25, 0.94, -0.02, -0.24, 0.47)$ \\
        $\boldsymbol{\gamma}^\top$ & $(-0.01, 0.35, 0.28, 0.37, 0.12, 0.08)$ \\
        $\boldsymbol{\Sigma}$ & $\begin{pmatrix}
           0.358 & -0.010 & 0.039 & 0.121 & 0.028 \\
           -0.01 & 0.001 & -0.003 & -0.005 & 0.002 \\
           0.039 & -0.003 & 0.043 & 0.034 & -0.019 \\
           0.121 & -0.005 & 0.034 & 0.069 & 0.003 \\
           0.028 & 0.002 & -0.019 & 0.003 & 0.017 \\
        \end{pmatrix}$ \\
        $\sigma$ & 5.27 \\
        \hline
    \end{tabular}
\end{table}


## Parameter convergence diagnostic
### Trace plot
\begin{figure} 
  \centering 
  \subfigure[mu]{ 
    \label{sub1}
    \includegraphics[width=2.0in, height = 1.4in]{parameters_burnin/Mu_parameters_time_series_plot.png} 
  } 
  \subfigure[Sigma matrix]{ 
    \label{sub2} 
    \includegraphics[width=2.0in, height = 1.4in]{parameters_burnin/Sigma_parameters_time_series_plot.png} 
  } \\
  \subfigure[gamma]{ 
    \label{sub3} 
    \includegraphics[width=2.0in, height = 1.4in]{parameters_burnin/Gamma_parameters_time_series_plot.png} 
  } 
  \subfigure[sigma]{ 
    \label{sub4} 
    \includegraphics[width=2.0in, height = 1.4in]{parameters_burnin/igma_parameters_time_series_plot.png} 
  } 
  \label{para1} 
\end{figure}

Through trace plots, it can be seen that the convergence speed of each parameter is very fast, and after 1000 iterations, all parameters except the intercept of $\boldsymbol\mu$ have converged with fluctuations, while the others have reached convergence.

\newpage



### Autocorrelation plot

The autocorrelation plots of each parameter for the 500 iterations after burn-in are shown below:

\begin{figure} 
  \centering 
  \subfigure[mu]{ 
    \label{sub1}
    \includegraphics[width=2.0in, height = 1.4in]{parameters_burnin/Mu_Parameters_ACF_Plot.png} 
  } 
  \subfigure[Sigma matrix]{ 
    \label{sub2} 
    \includegraphics[width=2.0in, height = 1.4in]{parameters_burnin/Sigma_Parameters_ACF_Plot.png} 
  } \\
  \subfigure[gamma]{ 
    \label{sub3} 
    \includegraphics[width=2.0in, height = 1.4in]{parameters_burnin/Gamma_Parameters_ACF_Plot.png} 
  } 
  \subfigure[sigma]{ 
    \label{sub4} 
    \includegraphics[width=2.0in, height = 1.4in]{parameters_burnin/igma_Parameters_ACF_Plot.png} 
  } 
  \label{para1} 
\end{figure}

It can be seen from the plots that the autocorrelation of each parameter decreases rapidly and eventually stabilizes near zero.

### Histogram plot
\begin{figure} 
  \centering 
  \subfigure[mu]{ 
    \label{sub1}
    \includegraphics[width=2.0in, height = 1.4in]{parameters_burnin/Mu_Parameters_Histogram_Plot.png} 
  } 
  \subfigure[Sigma matrix]{ 
    \label{sub2} 
    \includegraphics[width=2.0in, height = 1.4in]{parameters_burnin/Sigma_Parameters_Histogram_Plot.png} 
  } 
  \label{para1} 
\end{figure}

\newpage

## Hyperparameter Value of choosing
\textbf{Hyperparameter Value}
\begin{itemize}
 \item Search window $a=0.1$ 
 \item Burn-in $=8000$ 
 \item Resulting acceptance rate $=0.418$ 
\end{itemize}

## Posterior summaries of $\boldsymbol\gamma$
Posterior summaries and 95% credible intervals of $\boldsymbol\gamma$ is shown in table \ref{table:sum} and table \ref{table:ci}. We are mainly interested in answering two questions. Are there seasonal differences in hurricane wind speeds? Is there evidence to support the claim that hurricane wind speeds have been increasing over the years? The convergence of parameter $\gamma_{year}$ and $\gamma_{active}$ is shown in figure \ref{Year} and figure \ref{Active}. The two parameters converged after MCMC, and $\gamma_{active}$ had a better performance on convergence than $\gamma_{year}$. Thus we could answer the two questions using the 95% credible intervals. Since the credible intervals for both parameters contain zero, the conclusion is that there is no seasonal or yearly difference in hurricane wind speeds.

## Hurricane wind speed prediction
Given the estimates of parameters $\boldsymbol{\gamma}$ and $\boldsymbol\beta_i$ which is the coefficients associated the $i$th hurricane, the predicted wind speed of the $i$-th hurricane at $t+6$ time stamp, denoted as $\hat{Y}_i(t+6)$ could be computed as:
$$\hat{Y}_i(t+6) = \mathbf{Z}_i(t)^\top\hat{\boldsymbol\beta}_i  + \mathbf{X}_i^\top \hat{\boldsymbol{\gamma}},$$
where $\bm{\beta}_i = (\beta_{0,i}, \beta_{1,i}, ..., \beta_{4,i})^\top$, and $\mathbf{Z}_i(t) = (1, \ Y_i(t), \ \Delta_{i,1}(t), \ \Delta_{i,2}(t), \ \Delta_{i,3}(t))^\top$.\par

Based on the burn-in number $8000$ as concluded in MCMC parameter convergence diagnostic section, we calculated the parameters to be used to make prediction, and predict the wind speeds of each hurricane at each time stamp, except for the first two time stamps. We computed the RMSE and R-squared of each hurricane, as partly shown in the table \ref{table:summary}. It can be observed that different hurricanes perform variously on RMSE and R-squared. Generally the RMSE for selected hurricanes is around $3$ to $8$, and the R-squared is within $0.7$ to $1.0$. However, there is also extremely low R-squared($0.30$ as shown) and high RMSE($9.64$ as shown).\par

The prediction performance on several chosen example hurricanes is shown in figure \ref{Time series prediction plot} and figure \ref{Prediction vs. observation}. As shown in figure \ref{Time series prediction plot}, the predicted wind speed overall nicely fit the observed wind speed at each time index of those hurricanes, though performance is better on example hurricane 'ABLE.1951' than other examples. According to figure \ref{Prediction vs. observation}, the prediction and observation data points fit well as a linear line with slope $=1$. Digging deeper, the Bayesian model performs much better when the wind speed is stable, but worse when there exits some fluctuations of wind speed. More specifically, the Bayesian model's prediction has a latency in responding to the fluctuation of observed wind speed, and the changing of predicted speed is generally one unit time index behind observed speed.\par

The overall RMSE performance of difference hurricanes is shown in figure \ref{RMSE distribution}. And the overall R-squared performance of difference hurricanes is shown in figure \ref{$R^2$ distribution}. The RMSE follows an very right-skewed distribution, with most RMSEs distributed around $2$ to $6$, and distribution peak is around $3.5$. The distribution of R-squared then follows a very left-skewed distribution with most of the values distributed from $0.875$ to $1$, and the peak is around $0.94$. There also exists some extremely large RMSEs and small R-squareds, which may need further investigation.\par

Furthermore, we examined the distribution of RMSE across various properties of hurricanes is shown in figure \ref{RMSE under different natures} and figure \ref{RMSE under different months}. We observed that hurricanes belong to nature of "Not Rated" and "Tropical Storm" have an average higher RMSE than other hurricanes. Besides, hurricanes happening in summer from June to September, also have higher RMSE than other months.\par


# Discussion
## MCMC parameters convergence problem

## Prediction latency of wind speed change

# Group Contributions {-}

Hongjie Liu worked on mathematical derivations and implementing the MCMC algorithm in R. Additionally, he was responsible for writing section 2 of the report and delivering the presentation for task 1. I am grateful to my teammates for their thorough review of my mathematical derivations and R functions. Special thanks to Zijian, who also developed his own set of R functions for the MCMC algorithm and reviewed mine. I would also like to express my gratitude to Shaohan for identifying a critical error in my R function.


\clearpage

# Appendices {-}

## Figures and Tables {-}
\begin{table}[h]
\centering
\small
\caption{Posterior Summaries of $\boldsymbol\gamma$}
\label{table:sum}
\begin{tabular}{llcc}
\hline
\textbf{parameter} & \textbf{Mean} & \textbf{Standard Deviation} & \textbf{Median} \\ \hline
$\gamma_{year}$ & -0.010 & 0.009 & -0.011 \\
$\gamma_{active}$ & 0.002 & 0.053 & 0.002 \\
$\gamma_{ET}$ & 0.003 & 0.050 & 0.003 \\
$\gamma_{NR}$ & 0.0002 & 0.049 & -0.0003 \\
$\gamma_{SS}$ & 0.005 & 0.050 & 0.005 \\
$\gamma_{TS}$ & 0.01 & 0.057 & 0.01 \\\hline
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\small
\caption{95\% Credible Intervals of $\boldsymbol\gamma$}
\label{table:ci}
\begin{tabular}{lll}
\hline
\textbf{parameter} & \textbf{2.5\% Quantile} & \textbf{97.5\% Quantile} \\ \hline
$\gamma_{year}$ & -0.029 & 0.008  \\
$\gamma_{active}$ & -0.102 & 0.104  \\
$\gamma_{ET}$ & -0.096 & 0.098  \\
$\gamma_{NR}$ & -0.098 & 0.095  \\
$\gamma_{SS}$ & -0.096 & 0.104  \\
$\gamma_{TS}$ & -0.105 & 0.119  \\\hline
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\small
\caption{Summary of RMSE and R-squared for selected hurricanes}
\label{table:summary}
\begin{tabular}{llcc}
\hline
\textbf{ID} & \textbf{Year} & \textbf{RMSE} & \textbf{R-squared} \\ \hline
ABBY.1960 & 1960 & 8.8804 & 0.7700 \\
ABBY.1964 & 1964 & 9.6430 & 0.3033 \\
ABBY.1968 & 1968 & 3.5043 & 0.9360 \\
ABLE.1950 & 1950 & 3.6755 & 0.9813 \\
ABLE.1951 & 1951 & 3.4802 & 0.9767 \\
ABLE.1952 & 1952 & 4.5183 & 0.9583 \\
AGNES.1972 & 1972 & 5.2483 & 0.8881 \\
ALBERTO.1982 & 1982 & 8.0473 & 0.7499 \\
ALBERTO.1988 & 1988 & 2.6121 & 0.7420 \\
ALBERTO.1994 & 1994 & 4.3941 & 0.8807 \\
ALBERTO.2000 & 2000 & 3.7896 & 0.9625 \\
ALBERTO.2006 & 2006 & 4.3591 & 0.7882 \\
ALBERTO.2012 & 2012 & 3.2193 & 0.8036 \\
ALEX.1998 & 1998 & 2.9351 & 0.7289 \\
ALEX.2004 & 2004 & 5.4552 & 0.9539 \\ \hline
\end{tabular}
\end{table}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{jacky_part_pic/year.png}
  \caption{Time series plot of $\gamma_{year}$}
  \label{Year}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{jacky_part_pic/active.png}
  \caption{Time series plot of $\gamma_{active}$}
  \label{Active}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{predic_plots/b_merge.png}
  \caption{Time series prediction plot}
  \label{Time series prediction plot}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{predic_plots/a_1_4.png}
  \caption{Prediction vs. observation}
  \label{Prediction vs. observation}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{predic_plots/rmse1.png}
  \caption{RMSE distribution}
  \label{RMSE distribution}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{predic_plots/R_square.png}
  \caption{$R^2$ distribution}
  \label{$R^2$ distribution}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{predic_plots/rmse_nature.png}
  \caption{RMSE under different natures}
  \label{RMSE under different natures}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{predic_plots/months1.png}
  \caption{RMSE under different months}
  \label{RMSE under different months}
\end{figure}

\clearpage

## R Code {-}

```{r eval=FALSE}
# Gibbs sampling for B
B_sample <- function(mu, Sigma, gamma, sigma) {
  Sigma.inv <- solve(Sigma)
  B_mean_cov <- function(i) {
    cov <- solve(Sigma.inv + 1/sigma^2 * t(Z[[i]]) %*% Z[[i]])
    mean <- cov %*% (Sigma.inv %*% mu + 1/sigma^2 * colSums((Y[[i]] - (X[i,] %*% gamma)[,]) * Z[[i]]))
    list(mean = mean, cov = cov)
  }
  mean_cov_list <- lapply(1:n, B_mean_cov)
  B <- sapply(mean_cov_list, function(x) {mvrnorm(mu = x$mean, Sigma = x$cov)})
  return(B)
}

# Gibbs sampling for mu
mu_sample <- function(B, Sigma) {
  cov <- V %*% solve(n*V + Sigma)
  mean <- cov %*% rowSums(B)
  mu <- mvrnorm(mu = mean, Sigma = cov)
  return(mu)
}

# Gibbs sampling for Sigma matrix
Sigma_sample <- function(B, mu) {
  Sigma.inv <- rWishart(n = 1, Sigma = solve(S + (B - mu) %*% t(B - mu)), df = n + nu)[,,]
  Sigma <- solve(Sigma.inv)
  return(Sigma)
}

# Gibbs sampling for gamma
gamma_sample <- function(B, sigma) {
  X_trans <- sqrt(m) * X
  cov <- solve(400*diag(6) + 1/sigma^2 * t(X_trans) %*% X_trans)
  total <- rowSums(sapply(1:n, function(i) sum(Z[[i]] %*% B[,i] - Y[[i]]) * X[i,]))
  mean <- cov %*% (-1/sigma^2 * total)
  gamma <- mvrnorm(mu = mean, Sigma = cov)
  return(gamma)
}

# MH algorithm for sigma
sigma_sample <- function(sigma, B, gamma, a) {
  sigma_new <- sigma + (runif(1) - 0.5) * 2 * a # candidate sigma
  if (sigma_new <= 0) {
    return(sigma)
  }
  RSS <- sum(sapply(1:n, function(i) sum((Y[[i]] - Z[[i]] %*% B[,i] - (X[i,] %*% gamma)[,])^2)))
  log_kernal_ratio <- -sum(m) * log(sigma_new/sigma) +
    log(1 + (sigma/10)^2) - log(1 + (sigma_new/10)^2) -
    0.5 * (1/sigma_new^2 - 1/sigma^2) * RSS
  log_prob <- min(0, log_kernal_ratio)
  sigma <- ifelse(log_prob > log(runif(1)), sigma_new, sigma)
  return(sigma)
}

# MCMC algorithm
MCMC <- function(B0, mu0, Sigma0, gamma0, sigma0, a, iter) {
  B <- B0
  mu <- mu0
  Sigma <- Sigma0
  gamma <- gamma0
  sigma <- sigma0
  res <- vector("list", iter)
  for (i in 1:iter) {
    B <- B_sample(mu, Sigma, gamma, sigma)
    mu <- mu_sample(B, Sigma)
    Sigma <- Sigma_sample(B, mu)
    gamma <- gamma_sample(B, sigma)
    sigma <- sigma_sample(sigma, B, gamma, a)
    res[[i]] <- list(B = B, mu = mu, Sigma = Sigma, gamma = gamma, sigma = sigma)
  }
  return(res)
}
```

\begin{center}
\hypertarget{Code 1}{Code 1: A hybrid MCMC
algorithm consisting of Gibbs steps and Metropolis-Hastings steps}
\end{center}

\clearpage

## Derivation of Conditional Posterior Distribution for Each Parameter {-}
1. $\mathbf{B}$:
$$\begin{aligned}
&\ \pi(\boldsymbol\beta_i\mid \boldsymbol{\mu}^\top,\boldsymbol{\Sigma},\boldsymbol\gamma^\top,\sigma,\boldsymbol{Y}^\top)\\
\propto&\ \exp\left[-\frac{1}{2}(\boldsymbol\beta_i-\boldsymbol\mu)^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol\beta_i-\boldsymbol\mu)-\frac{1}{2\sigma^2}\sum_{j=1}^{m_i}(Y_{i,j}-\mathbf Z_{i,j-1}^\top\boldsymbol\beta_i-\mathbf{X}_i^\top\boldsymbol\gamma)^2\right]\\
\propto&\ \exp\left[-\frac{1}{2}\left((\boldsymbol\beta_i-\boldsymbol\mu)^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol\beta_i-\boldsymbol\mu)+\frac{1}{\sigma^2}\sum_{j=1}^{m_i}(-2\boldsymbol\beta_i^\top(Y_{i,j}-\mathbf{X}_i^\top\boldsymbol\gamma)\mathbf Z_{i,j-1}+\boldsymbol\beta_i^\top(\mathbf Z_{i,j-1}\mathbf Z_{i,j-1}^\top)\boldsymbol\beta_i)\right)\right]\\
\propto&\ \exp\left\{-\frac{1}{2}\left[\boldsymbol\beta_i^\top\left(\boldsymbol{\Sigma}^{-1}+\frac{1}{\sigma^2}\sum_{j=1}^{m_i}\mathbf Z_{i,j-1}\mathbf Z_{i,j-1}^\top\right)\boldsymbol\beta_i-2\boldsymbol\beta_i^\top\left(\boldsymbol{\Sigma}^{-1}\boldsymbol\mu+\frac{1}{\sigma^2}\sum_{j=1}^{m_i}(Y_{i,j}-\mathbf{X}_i^\top\boldsymbol\gamma)\mathbf Z_{i,j-1}\right)\right]\right\}.
\end{aligned}$$
Thus we have
$$\begin{aligned}\\
&\ \boldsymbol\beta_i\mid \boldsymbol{\mu}^\top,\boldsymbol{\Sigma},\boldsymbol\gamma^\top,\sigma,\boldsymbol{Y}^\top\\
\sim&\ N\left(\left(\boldsymbol{\Sigma}^{-1}+\frac{1}{\sigma^2}\sum_{j=1}^{m_i}\mathbf Z_{i,j-1}\mathbf Z_{i,j-1}^\top\right)^{-1}\left(\boldsymbol{\Sigma}^{-1}\boldsymbol\mu+\frac{1}{\sigma^2}\sum_{j=1}^{m_i}(Y_{i,j}-\mathbf{X}_i^\top\boldsymbol\gamma)\mathbf Z_{i,j-1}\right), \left(\boldsymbol{\Sigma}^{-1}+\frac{1}{\sigma^2}\sum_{j=1}^{m_i}\mathbf Z_{i,j-1}\mathbf Z_{i,j-1}^\top\right)^{-1}\right).\end{aligned}$$
2. $\boldsymbol{\mu}$:
$$\begin{aligned}
&\ \pi(\boldsymbol{\mu}\mid \mathbf{B}^\top,\boldsymbol{\Sigma},\boldsymbol\gamma^\top,\sigma,\boldsymbol{Y}^\top)\\
\propto&\ \exp\left[-\frac{1}{2}\left(\sum_{i=1}^n(\boldsymbol\beta_i-\boldsymbol\mu)^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol\beta_i-\boldsymbol\mu)+\boldsymbol\mu^\top\boldsymbol{V}^{-1}\boldsymbol\mu\right)\right]\\
\propto&\ \exp\left\{-\frac{1}{2}\left[\boldsymbol\mu-(n\boldsymbol\Sigma^{-1}+\boldsymbol V^{-1})^{-1}\boldsymbol\Sigma^{-1}\left(\sum_{i=1}^n\boldsymbol\beta_i\right)\right]^\top(n\boldsymbol\Sigma^{-1}+\boldsymbol V^{-1})\left[\boldsymbol\mu-(n\boldsymbol\Sigma^{-1}+\boldsymbol V^{-1})^{-1}\boldsymbol\Sigma^{-1}\left(\sum_{i=1}^n\boldsymbol\beta_i\right)\right]\right\}\\
\propto&\ \exp\left\{-\frac{1}{2}\left[\boldsymbol\mu-\boldsymbol V(n\boldsymbol V+\boldsymbol\Sigma)^{-1}\left(\sum_{i=1}^n\boldsymbol\beta_i\right)\right]^\top(\boldsymbol V(n\boldsymbol V+\boldsymbol\Sigma)^{-1})^{-1}\left[\boldsymbol\mu-\boldsymbol V(n\boldsymbol V+\boldsymbol\Sigma)^{-1}\left(\sum_{i=1}^n\boldsymbol\beta_i\right)\right]\right\}.
\end{aligned}$$
Thus we have
$$\boldsymbol{\mu}\mid \mathbf{B}^\top,\boldsymbol{\Sigma},\boldsymbol\gamma^\top,\sigma,\boldsymbol{Y}^\top\sim N\left(\boldsymbol V(n\boldsymbol V+\boldsymbol\Sigma)^{-1}\left(\sum_{i=1}^n\boldsymbol\beta_i\right), \boldsymbol V(n\boldsymbol V+\boldsymbol\Sigma)^{-1}\right).$$
3. $\boldsymbol{\Sigma}$:
$$\begin{aligned}
\pi(\boldsymbol{\Sigma}\mid\mathbf{B}^\top,\boldsymbol{\mu}^\top,\boldsymbol\gamma^\top,\sigma,\boldsymbol{Y}^\top)
\propto&\ |\boldsymbol{\Sigma}|^{-(n+\nu+6)/2}\exp\left[-\frac{1}{2}\left(\sum_{i=1}^n(\boldsymbol\beta_i-\boldsymbol\mu)^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol\beta_i-\boldsymbol\mu)+\mathrm{tr}(\boldsymbol{S}\boldsymbol{\Sigma}^{-1})\right)\right]\\
\propto&\ |\boldsymbol{\Sigma}|^{-(n+\nu+6)/2}\exp\left[-\frac{1}{2}\mathrm{tr}\left(\left(\boldsymbol{S}+\sum_{i=1}^n(\boldsymbol\beta_i-\boldsymbol\mu)(\boldsymbol\beta_i-\boldsymbol\mu)^\top\right)\boldsymbol{\Sigma}^{-1}\right)\right].
\end{aligned}$$
Thus we have
$$\boldsymbol{\Sigma}\mid \mathbf{B}^\top,\boldsymbol{\mu}^\top,\boldsymbol\gamma^\top,\sigma,\boldsymbol{Y}^\top\sim \mathcal{W}^{-1}\left(\boldsymbol{S}+\sum_{i=1}^n(\boldsymbol\beta_i-\boldsymbol\mu)(\boldsymbol\beta_i-\boldsymbol\mu)^\top, n+\nu\right).$$
4. $\boldsymbol\gamma$:
$$\begin{aligned}
&\ \pi(\boldsymbol\gamma\mid \mathbf{B}^\top,\boldsymbol{\mu}^\top,\boldsymbol{\Sigma},\sigma,\boldsymbol{Y}^\top)\\
\propto&\ \exp\left(-200\|\boldsymbol\gamma\|_2^2-\frac{1}{2\sigma^2}\sum_{i=1}^n\sum_{j=1}^{m_i}(Y_{i,j}-\mathbf Z_{i,j-1}^\top\boldsymbol\beta_i-\mathbf{X}_i^\top\boldsymbol\gamma)^2\right)\\
\propto&\ \exp\left\{-\frac{1}{2}\left[\boldsymbol\gamma^\top\left(400\boldsymbol I+\frac{1}{\sigma^2}\sum_{i=1}^nm_i\mathbf{X}_i\mathbf{X}_i^\top\right)\boldsymbol\gamma-2\boldsymbol\gamma^\top\left(-\frac{1}{\sigma^2}\sum_{i=1}^n\sum_{j=1}^{m_i}(\mathbf Z_{i,j-1}^\top\boldsymbol\beta_i-Y_{i,j})\mathbf{X}_i\right)\right]\right\}.
\end{aligned}$$
Thus we have
$$\begin{aligned}
&\ \boldsymbol\gamma\mid \mathbf{B}^\top,\boldsymbol{\mu}^\top,\boldsymbol{\Sigma},\sigma,\boldsymbol{Y}^\top\\
\sim&\ N\left(\left(400\boldsymbol I+\frac{1}{\sigma^2}\sum_{i=1}^nm_i\mathbf{X}_i\mathbf{X}_i^\top\right)^{-1}\left(-\frac{1}{\sigma^2}\sum_{i=1}^n\sum_{j=1}^{m_i}(\mathbf Z_{i,j-1}^\top\boldsymbol\beta_i-Y_{i,j})\mathbf{X}_i\right),\left(400\boldsymbol I+\frac{1}{\sigma^2}\sum_{i=1}^nm_i\mathbf{X}_i\mathbf{X}_i^\top\right)^{-1}\right).
\end{aligned}$$

